# DETRâ€‘Powered Image Captioning
**Efficient. Interpretable. Detectionâ€‘Driven.**
<br/>
_**Read the full technical write-up:**_ [DETR-Powered Efficient Image Captioning â€” LinkedIn (Aug 2025)](https://www.linkedin.com/pulse/reimagining-faster-image-captioning-detr-from-regions-tanaji-umbare-e3w3c)

A blazingâ€‘fast and smarter image captioning model built using [DETR (DEtection TRansformer)](https://arxiv.org/abs/2005.12872) to go beyond naÃ¯ve patchâ€‘based approaches.

---

## ğŸš€ Key Idea
Most image captioning models (e.g., ViTâ€‘GPT2, BLIP) treat images as a flat sequence of patches and generate captions purely in a sequenceâ€‘toâ€‘sequence manner. But **captioning is fundamentally about detecting and describing the key elements in a scene**â€”objects, their relationships, and context.

This work leverages DETR to:
- **Discover Regions of Interest** without hardcoded object classes.
- **Encode visual queries** via transformer layers for contextual fusion.
- **Generate captions** from those region tokens with a lightweight transformer decoder.

## ğŸ—ï¸ Architecture
![](architecture.png)


## ğŸ“Š Comparisons 

| Model                       | Image Resolution | BLEUâ€‘4 Score (%) | METEOR Score (%) | Total Time (ms) |
| :-------------------------- | :--------------: | :--------------: | :--------------: | :-------------:  |
| Showâ€¯&â€¯Tell             |     800â€¯Ã—â€¯800    |       27.7       |       23.7       |       210*       |
| Upâ€‘Down                 |     800â€¯Ã—â€¯800    |       36.2       |       27.0       |       620*       |
| MÂ²â€¯Transformer          |     800â€¯Ã—â€¯800    |       39.1       |       29.2       |       640*       |
| ViT-GPT2          |     800â€¯Ã—â€¯800    |       25.9       |       27.9       |       154       |
| BLIP-1          |     800â€¯Ã—â€¯800    |       38.6       |       -       |       197       |
| BLIP-2          |     800â€¯Ã—â€¯800    |       43.5       |       -        |       322       |
| **DETRâ€‘Powered Captioning** |     **800â€¯Ã—â€¯800**    |       **24.8**       |       **25.7**       |       **105**       |

*runtimes measured according NVIDIA P100, batch=1, identical default decode settings with identical image resultion approximately.


---

## Some Results 
![](Results/boy_computer.png)

![](Results/women_with_cat.png)


## ğŸ§° Install & Run

1. Clone the repository
```bash
git clone https://github.com/SohamUmbare/DETR_powered_image_captioning.git
cd DETR_powered_image_captioning
```

2. Create a virtual environment and install dependencies
```bash
python -m venv venv
source venv/bin/activate    # on Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. Directory Structure
```bash
â”œâ”€â”€ src/                    # source code
â”‚   â”œâ”€â”€ app.py              # FastAPI inference server
â”‚   â”œâ”€â”€ appGradio.py        # Gradio demo for HF Spaces
â”‚   â”œâ”€â”€ config.py           # configuration settings
â”‚   â”œâ”€â”€ detr_model.py       # loading DETR backbone
â”‚   â”œâ”€â”€ detr_nested_tensor.py # DETR tensor utilities
â”‚   â”œâ”€â”€ imgcap_model.py     # DETRWithCaption definition
â”‚   â”œâ”€â”€ generate.py         # caption generation script
â”‚   â”œâ”€â”€ evaluate.py         # evaluation script
â”‚   â”œâ”€â”€ train.py            # training script
â”‚   â””â”€â”€ dataset/
â”‚       â”œâ”€â”€ dataloader.py   # data loading pipeline
â”‚       â””â”€â”€ dataset.py      # dataset definitions
â””â”€â”€ requirements.txt
```

4. Run FastAPI server for inference
```bash
cd src
uvicorn app:app --reload --host 0.0.0.0 --port 3000
```

5. Launch Gradio demo locally
```bash
python appGradio.py
```

6. Generate a caption for an image
```bash
python generate.py --image path/to/image.jpg
```

7. Evaluate on test split
```bash
python evaluate.py --config config.py
```

8. Train the model 
```bash
python train.py --config config.py
```

---

## ğŸ¤– Live Demos & Integrations
- **Hugging Face Spaces:** [DETR Powered ImgCAP Playground](https://huggingface.co/spaces/SohamUmbare/DETR_powered_imgCAP)
- **Discord Bot:** [Try captions in real time via CAPbot](https://github.com/theSohamTUmbare/CAPbot)


## ğŸ‘¤ Author

**Soham Umbare**  
IIIT Raichur  
ğŸ“§ cs23b1068@iiitr.ac.in

---

â­ _If you find this work interesting, consider giving it a star on GitHub!_

---
ğŸ§‘â€ğŸ’» Happy Experimenting! ğŸ”¬
